# -*- coding: utf-8 -*-
# %%
#Pacotes utilizados
import numpy as np
import pandas as pd
import skfuzzy as skf

from skfuzzy import control as skc
from sklearn import datasets as data
from sklearn import model_selection as skms
from matplotlib import pyplot as plt
from beecolpy import abc

def apply_model(data, label, model, validate=False):
    #Regras
    sepal_length = skc.Antecedent(np.arange(0.5, 10, 0.1), 'sepal_length')
    petal_length = skc.Antecedent(np.arange(0.5, 10, 0.1), 'petal_length')
    petal_width = skc.Antecedent(np.arange(0.1, 5.0, 0.1), 'petal_width')
    group = skc.Consequent(np.arange(0, 2, 1e-2), 'Group')
    
    #Função de aplicação do modelo fuzzy
    sepal_length['Pequena'] = skf.trimf(sepal_length.universe, [0.5, 0.5, model[0]])    #<
    sepal_length['Media'] = skf.trimf(sepal_length.universe, [model[1], model[2], model[3]])
    sepal_length['Grande'] = skf.trimf(sepal_length.universe, [model[4], 10, 10])
    
    petal_length['Pequena'] = skf.trimf(petal_length.universe, [0.5, 0.5, model[5]])
    petal_length['Media'] = skf.trimf(petal_length.universe, [model[6], model[7], model[8]])
    petal_length['Grande'] = skf.trimf(petal_length.universe, [model[9], 10, 10])
    
    petal_width['Pequena'] = skf.trimf(petal_width.universe, [0.1, 0.1, model[10]])
    petal_width['Media'] = skf.trimf(petal_width.universe, [model[11], model[12], model[13]])
    petal_width['Grande'] = skf.trimf(petal_width.universe, [model[14], 5, 5])
    
    group['G0'] = skf.trimf(group.universe, [0, 0, model[15]])
    group['G1'] = skf.trimf(group.universe, [model[16], model[17], model[18]])
    group['G2'] = skf.trimf(group.universe, [model[19], 2, 2])
    
    regra_1 = skc.Rule(sepal_length['Media'] & petal_length['Pequena'] &
                       petal_width['Pequena'], group['G0'])
    
    regra_2 = skc.Rule(sepal_length['Media'] & petal_length['Media'] &
                       petal_width['Media'], group['G1'])
    
    regra_3 = skc.Rule(sepal_length['Grande'] & petal_length['Grande'] &
                       petal_width['Grande'], group['G2'])
    
    controle = skc.ControlSystem([regra_1, regra_2, regra_3])
    saida = skc.ControlSystemSimulation(controle)
    
    if validate:
        sepal_length.view()
        petal_length.view()
        petal_width.view()
        group.view()
    
    acertos = 0
    for i in range(len(data)):
        saida.input['sepal_length'] = data[i][0]
        saida.input['petal_length'] = data[i][2]
        saida.input['petal_width'] = data[i][3]
        saida.compute()
        
        if label[i] == np.round(saida.output['Group']):
            acertos += 1
        
    return acertos/len(data)

#Carrega o dataset e separa em conjunto de treino e validação
iris = data.load_iris()
dataset = np.column_stack((iris.data, iris.target))
dataset_columns = iris.feature_names + ['Group']

iris_train, iris_validate, label_train, label_validate = skms.train_test_split(
    iris.data, iris.target, test_size=0.5, random_state=12)

# %%
#Teste de correlação das características com os grupos
covariance = []
for i in range(len(iris_train[0])):
    temp_cov = np.cov(iris_train[:,i], label_train)[0,1]/ \
                        (np.std(iris_train[:,i]) * np.std(label_train))
    covariance.append(temp_cov)
print('\nCovariância normalizada de cada parâmetro com a classificação:\n',
      pd.DataFrame([covariance], columns=iris.feature_names),'\n')

#A correlação da "sepal width" é inversamente proporcional à classificação e seu
#valor é consideravelmente baixo (abs<0.5), sendo assim, esta variável será suprimida
#para reduzir os graus de liberdade necessários para o algoritmo de otimização
#resolver.

#As demais características são relevantes pois possuem covariância normalizada
#muito próximas de 1.

# %%
def cost_function(x):
    global iris_train, label_train
    
    try:
        #Verificação da validade dos valores testados
        #sepal_length
        if (x[0] <= x[1]):
            return np.nan
        
        for i in range(2,4):
            if x[i-1] > x[i]:
                return np.nan
            
        if (x[3] <= x[4]):
            return np.nan

        #petal_length
        if (x[5] <= x[6]):
            return np.nan
    
        for i in range(7,9):
            if x[i-1] > x[i]:
                return np.nan
        
        if (x[8] <= x[9]):
            return np.nan

        #petal_width
        if (x[10] <= x[11]):
            return np.nan
        
        for i in range(12,14):
            if x[i-1] > x[i]:
                return np.nan
        
        if (x[13] <= x[14]):
            return np.nan
        
        #group
        if (x[15] <= x[16]):
            return np.nan
        
        for i in range(17,19):
            if x[i-1] > x[i]:
                return np.nan
            
        if (x[18] <= x[19]):
            return np.nan
        
        #Caso os valores do modelo estejam dentro do tolerado, aplica
        #o modelo no conjunto de dados de treinamento.
        return apply_model(iris_train, label_train, x) * (-1)
    
    except:
        #Sim, as vezes os valores do modelo geram erro no pacote skfuzzy
        return np.nan

#Limites do espaço de busca
sep_le = [(0.5, 10) for _ in range(5)]
pet_le = [(0.5, 10) for _ in range(5)]
pet_wi = [(0.1, 5) for _ in range(5)]
g = [(0, 2) for _ in range(5)]
boundaries = sep_le + pet_le + pet_wi + g

#Usamos a colonia de abelhas artificial por ser um algoritmo mais rápido neste
#tipo de problema, e, já possui proteção contra NaNs, aumentando a probabilidade
#de convergência, contudo, qualquer algoritmo de otimização numérica
#capaz de avaliar sistemas multi-dimensionais com eficiência (nesse caso no R^20)
#pode ser aplicado aqui.
abc_obj = abc(cost_function, boundaries, scouts=0.1, iterations=1, nan_protection=True)
total_iterations = 0 #Histórico do total de iterações executadas
cost_history = [] #Historico do avanço da função custo

# %%
#Executa a otimização
cost = cost_function(abc_obj.get_solution())
min_cost = 0.9
counter_max = 1000000 #Executa até 1.000.000 iterações
counter = 0
while (np.isnan(cost) or (abs(cost) < min_cost)) and (counter < counter_max):
    abc_obj.fit()
    cost = cost_function(abc_obj.get_solution())
    cost_history.append(abs(cost))
    total_iterations += abc_obj.get_status()[0]
    counter += 1

plt.figure()
plt.plot(cost_history, 'r*:', label='Assertividade do treinamento')
plt.grid(True)
plt.legend(loc='best')

print('\nAssertividade do treinamento:' + str(cost_function(abc_obj.get_solution())*100) + '%\n')
model = abc_obj.get_solution()

# %%
#Validação
#Modelo encontrado pela meta-heuristica (salvo para evitar acidentes)
# model = [7.820832190853921, 2.31482724609497, 5.6662017396228395,
#           6.671917724767254, 2.0239317860615778, 4.40492983366766,
#           2.018972446124932, 6.332068172496837, 8.53634119822423,
#           1.9273473221936863, 1.3584252936962893, 0.9409301064887465,
#           2.054738187216678, 4.806052425602064, 0.10647104158758393,
#           1.1433952151944697, 1.0483687468076053, 1.6248452828555107,
#           1.7368569274222652, 0.8436899666614793]

fim = apply_model(iris_validate, label_validate, model, validate=True)
print('\nAssertividade do algoritmo: ' + str(fim*100) + '%\n')
